{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMQYA/YxEy4eAExl40NlZs4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanielDialektico/dialektico-machine-learning-practices/blob/main/notebooks/Machine%20Learning/Aprendizaje%20Supervisado/descenso_de_gradiente.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://dialektico.com/wp-content/uploads/2023/03/MiniLogoW4.png\" alt=\"Dial√©ktico Logo\" />"
      ],
      "metadata": {
        "id": "ms6VNhA5VMKS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Descenso de gradiente üå†**\n",
        "---"
      ],
      "metadata": {
        "id": "fW2xRDMsVQQy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Introducci√≥n**"
      ],
      "metadata": {
        "id": "22eZjG8uVTi6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el recorrido [introductorio al descenso de gradiente](https://dialektico.com/introduccion-al-descenso-de-gradiente/) hemos revisado c√≥mo es el funcionamiento interno de este artefacto para la optimizaci√≥n de **funciones de costo** y su uso para entrenamiento de modelos de **aprendizaje autom√°tico**.\n",
        "\n",
        "En esta pr√°ctica veremos c√≥mo luce la evoluci√≥n de los par√°metros para un nuevo modelo, operando sobre un conjunto de datos que no hab√≠amos utilizado anteriormente.  \n",
        "\n",
        "<br>\n",
        "<center><img src=\"https://dialektico.com/wp-content/uploads/2025/07/DGG_Colab.png\" width=\"300\" /></center>"
      ],
      "metadata": {
        "id": "TIfdetXDVYJy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "LHAgeJWwXnHZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Objetivo**"
      ],
      "metadata": {
        "id": "kMJBHShvXkV6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El objetivo de esta pr√°ctica es entrenar un modelo de aprendizaje supervisado utilizando el algoritmo de descenso de gradiente.\n",
        "\n",
        "Debemos seguir los siguientes pasos:\n",
        "\n",
        "* Comprender el problema y realizar un an√°lisis exploratorio de datos.\n",
        "* Aplicar preprocesamiento de datos.\n",
        "* Enrenar el modelo con descenso de gradiente.\n",
        "* Evaluar el modelo y generar un reporte de resultados.\n",
        "\n",
        "Con esto comprenderemos c√≥mo es que el descenso de gradiente es un recurso √∫til para el entrenamiento de modelos que hemos explorado con anterioridad.\n",
        "\n",
        "<br>\n",
        "<center><img src=\"https://dialektico.com/wp-content/uploads/2025/08/DGG_Colab_mision.png\" width=\"400\" /></center>"
      ],
      "metadata": {
        "id": "bZV41gzkX3F5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "eXmuWJm2bGOZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Planteamiento del problema"
      ],
      "metadata": {
        "id": "_313ftBASD7o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta ocasi√≥n haremos uso de nuestras habilidades como cient√≠ficxs de datos y atenderemos un nuevo caso: **predicci√≥n de tarifas de taxis**.\n",
        "\n",
        "Para esto utilizaremos un conjunto de datos con las siguientes caracter√≠sticas:\n",
        "* **Distancia en kil√≥metros** (Trip_Distance_km): La longitud del viaje en kil√≥meros.\n",
        "* **Momento del viaje** (Time_of_Day): Si se realiz√≥ durante la ma√±ana, tarde o noche.\n",
        "* **D√≠a de la semana** (Day_of_Week): D√≠a de la semana en que se efectu√≥ el viaje.\n",
        "* **Condiciones del tr√°fico** (Traffic_Conditions): Indicador de las caracer√≠sticas del tr√°fico (ligero, medio, pesado).\n",
        "* **Cantidad de pasajeros** (Passenger_Count): N√∫mero de pasajeros para el viaje.\n",
        "* **Condici√≥n clim√°tica** (Weather): Datos categ√≥ricos del clima (despejado, lluvia, nieve).\n",
        "* **Duraci√≥n del viaje en minutos** (Trip_Duration_Minutes): Tiempo total del viaje.\n",
        "* **Tarifa por kil√≥mero en d√≥lares** (Per_Km_Rate): La tarifa cobrada por kil√≥metro recorrido.\n",
        "* **Tarifa cobrada por minuto en d√≥lares** (Per_Minute_Rate): La tarifa cobrada por minuto de duraci√≥n del viaje.\n",
        "* **Tarifa base en d√≥lares** (Base_Fare): La tarifa base inicial del trayecto en taxi antes de aplicar cualquier recargo por distancia o tiempo.\n",
        "* **Monto de la tarifa final en d√≥lares** (Trip_Price): El costo del viaje.\n",
        "\n",
        "Nuestra misi√≥n es entrenar un modelo que, basado en las variables del conjunto de datos, nos permita estimar el costo de un viaje (monto de la tarifa)."
      ],
      "metadata": {
        "id": "VFWeaIk7SHPn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<center><img src=\"https://dialektico.com/wp-content/uploads/2025/08/DDG_D2.jpg\" width=\"400\" /></center>"
      ],
      "metadata": {
        "id": "aD8QYFXITobQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "¬øLo sabes? Dado que la tarifa es un n√∫mero de tipo continuo, se trata de un problema de **regresi√≥n**, para lo cual podemos utilizar una regresi√≥n lineal multivariable."
      ],
      "metadata": {
        "id": "AL6vtGmETr-X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "o7_4VEv3T3bf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preparaci√≥n de datos y librer√≠as"
      ],
      "metadata": {
        "id": "y7tgxFD1bFyB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comenzaremos por cargar las librer√≠as que utilizaremos. Volveremos a utilizar **mlektic**, la cual nos permite aplicar descenso de gradiente de manera sencilla, y obtener un reporte automatizado de resultados (la instalaci√≥n puede tardar un poco)."
      ],
      "metadata": {
        "id": "NbHBQk0AUB13"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Nota*:** *Las instalaciones se realizan a pesar de que algunas librer√≠as ya est√°n integradas de forma nativa en Colab, esto para asegurar que el Notebook no presente problemas de ejecuci√≥n si se dan cambios en la sintaxis entre versiones de librer√≠as.*"
      ],
      "metadata": {
        "id": "l7hoEI_1dw7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se instalan las librer√≠as necesarias.\n",
        "!pip install mlektic==1.0.8"
      ],
      "metadata": {
        "id": "Sby_14AlVTza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se importan las librer√≠as y se establecen configuraciones adicionales:"
      ],
      "metadata": {
        "id": "E61x-fZ7jwQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se importan las librer√≠as.\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from mlektic.linear_reg import LinearRegressionArcht\n",
        "from mlektic.reporting import ReportBuilder\n",
        "from mlektic.plot_utils import plot_cost\n",
        "from mlektic import preprocessing, methods\n",
        "from google.colab import files\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "\n",
        "# Se filtran las advertencias.\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Se define el estilo de las gr√°ficas.\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "\n",
        "# Se define el despliegue de flotantes en dataframes.\n",
        "pd.options.display.float_format = '{:.2f}'.format"
      ],
      "metadata": {
        "id": "9BmOjSybfTMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora cargamos el conjunto de datos con el que trabajaremos:"
      ],
      "metadata": {
        "id": "63T8VLZXgTHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se toma el conjunto de datos de un repositorio de GitHub.\n",
        "dataset = pd.read_csv('https://raw.githubusercontent.com/DanielDialektico/dialektico-machine-learning-practices/refs/heads/main/data/viajes_taxi.csv', encoding='latin1')\n",
        "dataset"
      ],
      "metadata": {
        "id": "vZekqrpYf60h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora mostramos informaci√≥n general de los datos:"
      ],
      "metadata": {
        "id": "JQl68RDTbNxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.info()"
      ],
      "metadata": {
        "id": "plzG9MbVVS1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se imprime una tabla con datos estad√≠sticos de cada variable del conjuto de datos.\n",
        "dataset.describe()"
      ],
      "metadata": {
        "id": "-TZ1drypVRuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "HiqnxjSxicu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos notar informaci√≥n de valor de manera r√°pida:\n",
        "* Tenemos valores nulos en todas las variables, ya que deber√≠an ser 1000 registros no nulos de cada una.\n",
        "* Existen valores no num√©ricos.\n",
        "* En algunas variables la desviaci√≥n est√°ndar es en apariencia alta.\n",
        "* Los m√≠mimos y m√°ximos globales est√°n bastante separados (valores m√°s altos y m√°s bajos del conjunto)."
      ],
      "metadata": {
        "id": "UsembxvlbhPo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "U90XFf3ib8mg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocesamiento de datos**"
      ],
      "metadata": {
        "id": "oPAfZfkejBh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Haremos un preprocesamiento r√°pido de los datos con las siguientes etapas:\n",
        "\n",
        "* Limpieza de valores nulos.\n",
        "* Transformaci√≥n de datos categ√≥ricos en num√©ricos.\n",
        "* Limpieza de valores at√≠picos.\n",
        "* Estandarizaci√≥n de datos."
      ],
      "metadata": {
        "id": "BAdDbhQnb95o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Nota***: *es posible realizar diferentes an√°lisis y etapas de preprocesamiento. Aqu√≠ lo haremos de forma sencilla para evitar extendernos en la pr√°ctica, pero eres libre de realizar las adecuaciones que consideres necesarias al conjunto de datos.*"
      ],
      "metadata": {
        "id": "V_11sCopcr3Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "K7AlnNsk9MbP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Limpieza de datos"
      ],
      "metadata": {
        "id": "kq6vxL0KdI9A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comenzaremos por mostrar el n√∫mero de valores nulos, a pesar de que pudimos vislumbrarlo en las tablas antes invocadas:"
      ],
      "metadata": {
        "id": "bg19O0m1diTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se imprimen los valores nulos de cada columna.\n",
        "dataset.isnull().sum()"
      ],
      "metadata": {
        "id": "k9aE2PaI4AAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En promedio tenemos 50 valores nulos por variable, lo cual representa un 5% de la muestra total. Dado que queremos utilizar un proceso de limpieza simple, eliminamos los valores nulos:"
      ],
      "metadata": {
        "id": "gjUNO0I_dyUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Removemos los valores nulos.\n",
        "dataset_wnulls = dataset.dropna()\n",
        "\n",
        "# Mostramos los nulos.\n",
        "dataset_wnulls.isnull().sum()"
      ],
      "metadata": {
        "id": "BLvk6lW0dx0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora que hemos realizado la remoci√≥n de los datos nulos, buscaremos alg√∫n tipo de valor extra√±o en las variables categ√≥ricas (con valores cualitativos), mostrando sus valores √∫nicos:"
      ],
      "metadata": {
        "id": "OLlHnybYeVIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se seleccionan columnas tipo object (valores cualitativos).\n",
        "obj_cols = dataset_wnulls.select_dtypes(include=\"object\").columns\n",
        "\n",
        "# Se imprimen los valores √∫nicos de cada columna.\n",
        "for col in obj_cols:\n",
        "    print(f\"Columna: {col}\")\n",
        "    print(f\"Valores √∫nicos: {dataset_wnulls[col].unique()}\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "vEX0ZNbVeo9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hemos comprobado que los valores no contienen alg√∫n tipo de error de escritura, por lo que podemos trabajar ahora en sustituir estos por valores num√©ricos."
      ],
      "metadata": {
        "id": "cq-ckmX-e0uJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "KLhzfBb1fPmw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tansformaci√≥n de datos"
      ],
      "metadata": {
        "id": "KI9euS_7fRNQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para transformar los datos utilizaremos la librer√≠a [scikit-learn](https://scikit-learn.org/stable/), con la funci√≥n `OrdinalEncoder`, que asignar√° n√∫meros a cada valor cualitativo basado en un orden que le hayamos dado a las variables. En este caso, es importante el orden, ya que los valores de las variables se relacionan de esta manera, por ejemplo: la ma√±ana es antes de la noche, y la magnitud del tr√°fico va de menor a mayor."
      ],
      "metadata": {
        "id": "VVt0031gfsDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se seleccionan las columnas categ√≥ricas a codificar.\n",
        "ord_cols = [\"Time_of_Day\", \"Day_of_Week\", \"Traffic_Conditions\", \"Weather\"]\n",
        "\n",
        "# Se define el orde de las categor√≠as.\n",
        "categories = [\n",
        "    [\"Morning\", \"Afternoon\", \"Evening\", \"Night\"],  # Tiempo del d√≠a.\n",
        "    [\"Weekday\", \"Weekend\"],                        # D√≠a de la semana.\n",
        "    [\"Low\", \"Medium\", \"High\"],                     # Condiciones del tr√°fico.\n",
        "    [\"Clear\", \"Rain\", \"Snow\"],                     # Clima.\n",
        "]\n",
        "\n",
        "# Se instancia el codificador a utilizar.\n",
        "enc = OrdinalEncoder(categories=categories, encoded_missing_value=-1)\n",
        "\n",
        "# Se codifican los valores.\n",
        "dataset_enc = dataset_wnulls.copy()\n",
        "dataset_enc[ord_cols] = enc.fit_transform(dataset_enc[ord_cols])\n",
        "\n",
        "# Se muestra la tabla con los valores codificados.\n",
        "dataset_enc.head()"
      ],
      "metadata": {
        "id": "bK9e1eWyhn1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificamos que se haya asignado un n√∫mero a cada valor categ√≥rico:"
      ],
      "metadata": {
        "id": "72FojHWhjhLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Columnas codificadas.\n",
        "cols = [\"Time_of_Day\", \"Day_of_Week\", \"Traffic_Conditions\", \"Weather\"]\n",
        "\n",
        "# Se imprimen los valores √∫nicos.\n",
        "for col in cols:\n",
        "    print(f\"Columna: {col}\")\n",
        "    print(dataset_enc[col].unique())\n",
        "    print(\"-\" * 40)"
      ],
      "metadata": {
        "id": "8ymQsSRhi8mI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "ififrNxXjtoA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Revisi√≥n de correlaci√≥n entre variables."
      ],
      "metadata": {
        "id": "ymSrG_d7jvSQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqu√≠ a√±adiremos una r√°pido vistazo de la correlaci√≥n entre las variables, esto nos permitir√° ver si existen variables con una fuerte correlaci√≥n, de tal forma que podamos eliminar algunas para evitar redundancia:"
      ],
      "metadata": {
        "id": "Zuz703rKku0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se obtiene la matriz de correlaci√≥n.\n",
        "corr = dataset_enc.corr(method=\"pearson\")\n",
        "corr"
      ],
      "metadata": {
        "id": "hYIwqDovju9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observamos que existe poca correlaci√≥n entre las variables, por lo que mantenemos todas para ser modeladas por la regresi√≥n lineal m√°s adelante. En este sentido de limpieza de variables, exsten m√©todos m√°s avanzados como el an√°lisis de componentes principales (ACP), pero lo dejaremos para trabajos futuros (de cualquier manera, recuerda que eres libre de aplicar el preprocesamiento que gustes a tus datos)."
      ],
      "metadata": {
        "id": "1rIAlu7DlCeI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "7-hyrfeslSqY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Eliminaci√≥n de datos at√≠picos"
      ],
      "metadata": {
        "id": "UzwDRFNolTi4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Proseguimos con la eliminaci√≥n de los valores at√≠picos. Idealmente, habr√≠a que revisar las distribuciones de los datos para decidir qu√© algoritmo utilizar para su detecci√≥n, pero lo haremos directamente con un m√©todo robusto llamado Median Absolute Deviation (desviaci√≥n absoluta de la mediana).\n",
        "\n",
        "\n",
        "Creamos nuestra funci√≥n para detecci√≥n de valores at√≠picos con numpy:"
      ],
      "metadata": {
        "id": "OWF3xuTSlW4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def drop_outliers_mad(df, threshold=3.5):\n",
        "    \"\"\"\n",
        "    Elimina filas con outliers usando Median Absolute Deviation (MAD).\n",
        "    - threshold: valores mayores son m√°s tolerantes (3.5 ‚âà criterio habitual).\n",
        "    \"\"\"\n",
        "    df_clean = df.copy()\n",
        "    num_cols = df_clean.select_dtypes(include=\"number\").columns\n",
        "    mask = pd.Series(True, index=df_clean.index)\n",
        "\n",
        "    for col in num_cols:\n",
        "        x = df_clean[col]\n",
        "        med = x.median()\n",
        "        mad = (x - med).abs().median()\n",
        "        if mad == 0:\n",
        "            continue  # evita divisi√≥n por cero en columnas constantes\n",
        "        robust_z = 0.6745 * (x - med).abs() / mad\n",
        "        mask &= (robust_z <= threshold) | x.isna()\n",
        "\n",
        "    return df_clean[mask]\n"
      ],
      "metadata": {
        "id": "4WJg_Dcllxvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplicamos la funci√≥n a nuestro conjunto de datos:"
      ],
      "metadata": {
        "id": "wKc1L_vomFfQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se aplica el m√©todo MAD al conjunto de datos.\n",
        "no_outliers_dataset = drop_outliers_mad(dataset_enc, threshold=3.5)\n",
        "\n",
        "# Se imprimen las dimensiones del conjunto de datos antes y despu√©s.\n",
        "print(\"Tama√±o antes de la limpieza:\", dataset_enc.shape)\n",
        "print(\"Tama√±o despu√©s de la limpieza:\", no_outliers_dataset.shape)"
      ],
      "metadata": {
        "id": "4hef0jJkl3JI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El resultado ha sido la remoci√≥n de 14 valores at√≠picos, lo cual representa un muy bajo porcentaje del conjunto de datos (aprox. 2.5%)."
      ],
      "metadata": {
        "id": "hcA_TiiZmSxI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "FwUPoiLzmymQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estandarizaci√≥n de datos"
      ],
      "metadata": {
        "id": "VWZ9ZO8amHl4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un paso t√≠pico en el preprocesamiento de los datos es la estandarizaci√≥n, la cual consiste en una transformaci√≥n que convierte los valores de cada variable a una escala comparable, haciendo que:\n",
        "\n",
        "\\begin{align}\n",
        "        \\text{media}=0, \\text{desviaci√≥n est√°ndar=1} \\tag{1.1}\n",
        "    \\end{align}\n",
        "\n",
        "Cuando se utilizan m√©todos de optimizaci√≥n como descenso de gradiente, se recomienda estandarizar los datos, ya que tener las variables en una misma escala acelera la convergencia y evita pasos desbalanceados."
      ],
      "metadata": {
        "id": "ztPsTUcdo0qo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Procedemos a escalar los datos utilizando `StandardScaler()` de scikit-learn, donde cuidamos el no estandarizar la variable objetivo, ya que buscamos mantener las predicciones en la escala original:"
      ],
      "metadata": {
        "id": "VxMeaGVJqDkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se define la variable objetivo.\n",
        "target_col = \"Trip_Price\"\n",
        "\n",
        "# Se separan las variables de entrada y salida.\n",
        "X = no_outliers_dataset.drop(columns=[target_col])\n",
        "y = no_outliers_dataset[target_col]\n",
        "\n",
        "# Se escalan los datos.\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Se reconstruye la tabla de datos.\n",
        "preprocessed_dataset = pd.DataFrame(\n",
        "    X_scaled,\n",
        "    columns=X.columns,\n",
        "    index=no_outliers_dataset.index\n",
        ")\n",
        "\n",
        "preprocessed_dataset[target_col] = y\n",
        "\n",
        "# Se muestra la tabla.\n",
        "preprocessed_dataset\n"
      ],
      "metadata": {
        "id": "QDKqMDcundPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hemos concluido con las etapas de preprocesamiento, recuerda que aqu√≠ lo hemos dejado simple, pero un buen preprocesamiento implica an√°lisis rigurosos, visualizaciones gr√°ficas, y diversos procesos contextualizados a las caracter√≠sticas de los datos.\n",
        "\n"
      ],
      "metadata": {
        "id": "ugzXlWQeq5Io"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<center><img src=\"https://dialektico.com/wp-content/uploads/2025/08/DDG_K3.jpg\" width=\"400\" /></center>"
      ],
      "metadata": {
        "id": "mdS4aHJhrclQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "mBuHFgPIrnGA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenamiento del modelo"
      ],
      "metadata": {
        "id": "Q7J1WZ7bro84"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para entrenar el modelo, utilizaremos una **regresi√≥n lineal** con mlektik, la cual utiliza [Pytorch](https://pytorch.org/) de forma subyacente para entrenar el modelo con descenso de gradiente. El descenso de gradiente se puede realizar con otras librer√≠as, pero aqu√≠ lo haremos con mlektik por su simplicidad y transparencia en la aplicaci√≥n a regresiones lineales y log√≠sticas."
      ],
      "metadata": {
        "id": "PI53NRy5rrap"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenaremos al modelo eligiendo los siguientes hiperpar√°metros explicados en el recorrido:\n",
        "* Tasa de aprendizaje = 0.05\n",
        "* Iteraciones = 10"
      ],
      "metadata": {
        "id": "xF0_UEppmv5I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adem√°s, utilizaremos el 80% de los datos para entrenamiento, y el 20% restante para evaluaci√≥n, esto lo haremos con `preprocessing.pd_dataset` de mlektic."
      ],
      "metadata": {
        "id": "REaj45jNB6i2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separamos las variables de entrada de la variable objetivo.\n",
        "cols = preprocessed_dataset.columns.drop(\"Trip_Price\").tolist()\n",
        "\n",
        "# Se separa el conjunto de datos para entrenamiento y prueba.\n",
        "train_set, test_set = preprocessing.pd_dataset(\n",
        "    preprocessed_dataset,\n",
        "    input_columns = cols,\n",
        "    output_column = \"Trip_Price\",\n",
        "    train_fraction = 0.8,\n",
        ")\n",
        "\n",
        "# Se selecciona el optimizador, en este caso, un descenso de gradiente,\n",
        "# con la tasa de aprendizaje seleccionada.\n",
        "optimizer = methods.optimizer_archt(\"sgd-standard\", learning_rate=0.05)\n",
        "\n",
        "# Se prepara la fase de entrenamiento, configurando 10 iteraciones.\n",
        "linreg = LinearRegressionArcht(\n",
        "    method     = \"batch\",\n",
        "    optimizer  = optimizer,\n",
        "    iterations = 10,\n",
        "    metric = \"r2\"\n",
        ")\n",
        "\n",
        "# Se entrena el modelo.\n",
        "linreg.train(train_set);"
      ],
      "metadata": {
        "id": "pzOBxxcD3Pli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ver√°s que se desglosaron algunos datos sobre la ejecuci√≥n, estas son las definiciones:\n",
        "*   **Epoch**: √©poca o n√∫mero de iteraci√≥n del entrenamiento.\n",
        "*   **Loss**: valor de la funci√≥n de p√©rdida.\n",
        "*   **R2**: m√©trica $R^2$ para calcular el rendimiento del modelo.\n",
        "\n"
      ],
      "metadata": {
        "id": "8mRpBLSSni6Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluamos el $R^2$ en el conjunto de pruebas:"
      ],
      "metadata": {
        "id": "jQgOE0q6pQL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linreg.eval(test_set, 'r2')"
      ],
      "metadata": {
        "id": "3_po2yRyATcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos notar que el $R^2$ indica un modelo deficiente, ya que, como hemos visto anteriormente, deber√≠a acercarse a $1$ para indicar un buen desempe√±o del modelo; por ello, buscaremos modificar los hiperpar√°metros utilizados."
      ],
      "metadata": {
        "id": "CKXeBHU9pbDw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "gZuvOwOnqMFH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuraci√≥n de hiperpar√°metros y generaci√≥n de reportes"
      ],
      "metadata": {
        "id": "y9nWUwhpqN8H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de hacer modificaciones en los par√°metros, quiero que aprendas c√≥mo generar un reporte autom√°tico del entrenamiento que acabas de ejecutar. Es bastante sencillo y r√°pido, simplementa se utiliza la funci√≥n ```ReportBuilder``` de mlektic.\n",
        "\n",
        "Solo debes pasar el modelo que entrenaste (en este caso, `linreg`), y de manera opcional, la descripci√≥n de tu conjunto de datos y las etapas de preprocesamiento.\n",
        "\n",
        "Lo hacemos de la siguiente manera:\n",
        "\n"
      ],
      "metadata": {
        "id": "y74bD0ZsqWB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Descripci√≥n opcional del conjunto de datos.\n",
        "dataset_description = \"Conjunto de datos de precios de viajes en Taxi\"\n",
        "\n",
        "# Descripci√≥n opcional del preprocesamiento de datos.\n",
        "preprocessing_steps = [\n",
        "    \"Limpieza de valores nulos.\",\n",
        "    \"Transformaci√≥n de datos categ√≥ricos en num√©ricos.\",\n",
        "    \"Limpieza de valores at√≠picos.\",\n",
        "    \"Estandarizaci√≥n de datos.\",\n",
        "]\n",
        "\n",
        "# Se utiliza el constructor de reportes, pasando el modelo y descripciones.\n",
        "builder = ReportBuilder(\n",
        "    mdl          = linreg,\n",
        "    dataset_name = dataset_description,\n",
        "    preprocessing = preprocessing_steps,\n",
        ")\n",
        "\n",
        "# Se genera el reporte.\n",
        "builder.to_html(\"reporte.html\")\n",
        "\n",
        "# Se descarga.\n",
        "files.download(\"reporte.html\")\n",
        "print('Reporte generado y descargado.')"
      ],
      "metadata": {
        "id": "t4SCv818qf33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El reporte deber√≠a haberse descargado autom√°ticamente, busca en tus descargas y abre el archivo *reporte.html*, donde encontrar√°s algo como esto:"
      ],
      "metadata": {
        "id": "odsWjNpxrz-P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<center><img src=\"https://dialektico.com/wp-content/uploads/2025/08/DDG_report.png\" width=\"800\" /></center>"
      ],
      "metadata": {
        "id": "eXpQH30SsA43"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<center><img src=\"https://dialektico.com/wp-content/uploads/2025/08/DDG_D3.png\" width=\"400\" /></center>"
      ],
      "metadata": {
        "id": "Zd2a8mVosTm_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Desglosaremos con m√°s detalle el reporte en lo subsiguiente, por el momento, buscaremos mejorar el desempe√±o del modelo.\n",
        "\n",
        "Haremos de nuevo el entrenamiento, pero modificando un hiperpar√°metro, el n√∫mero de iteraciones:\n",
        "* Tasa de aprendizaje = 0.05\n",
        "* Iteraciones = 50 (nuevo valor)"
      ],
      "metadata": {
        "id": "moEiJqdpte2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = methods.optimizer_archt(\"sgd-standard\", learning_rate=0.05)\n",
        "\n",
        "# Se entrena el modelo, seleccionando\n",
        "linreg = LinearRegressionArcht(\n",
        "    method     = \"batch\",\n",
        "    optimizer  = optimizer,\n",
        "    iterations = 50, # Nuevo valor\n",
        "    metric     = 'r2'\n",
        ")\n",
        "\n",
        "linreg.train(train_set);"
      ],
      "metadata": {
        "id": "HBiblKfkJwID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mostramos el valor de $R^2$ en el conjunto de datos de pruebas:"
      ],
      "metadata": {
        "id": "R_x1Q_VtucUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linreg.eval(test_set, 'r2')"
      ],
      "metadata": {
        "id": "SIa0wxbVuk1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hemos notado que el desempe√±o ha mejorado bastante, ya que $R^2$ se acerca mucho m√°s a $1$ de lo que se acercaba anteriormente. Esto implica que el modelo ha mejorado al a√±adir un mayor n√∫mero de iteraciones.\n",
        "\n",
        "Podemos observar c√≥mo evolucion√≥ el valor de la funci√≥n de p√©rdida con la siguiente gr√°fica:"
      ],
      "metadata": {
        "id": "LrElYh1FulxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "cost_history = linreg.get_cost_history()\n",
        "plot_cost(cost_history, dim = (7, 5))"
      ],
      "metadata": {
        "id": "5TCwW2Fwu_T3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Puedes notar que a lo largo de las iteraciones el valor de la funci√≥n de costo ha disminuido, por lo que el descenso de gradientes ha realizado bien su trabajo minimizando este valor a lo largo de las √©pocas."
      ],
      "metadata": {
        "id": "1D2zfEj2wq9_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como √∫ltimo paso, genera tu reporte:"
      ],
      "metadata": {
        "id": "5MSnszckw0UY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se utiliza el constructor de reportes, pasando el modelo y descripciones.\n",
        "builder = ReportBuilder(\n",
        "    mdl          = linreg,\n",
        "    dataset_name = dataset_description,\n",
        "    preprocessing = preprocessing_steps,\n",
        ")\n",
        "\n",
        "# Se genera el reporte.\n",
        "builder.to_html(\"reporte.html\")\n",
        "\n",
        "# Se descarga\n",
        "files.download(\"reporte.html\")\n",
        "print('Reporte generado y descargado.')"
      ],
      "metadata": {
        "id": "-_wEBAcGw7O3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "WLBLJr0nEZcO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Taxonom√≠a del reporte"
      ],
      "metadata": {
        "id": "ioNDvgshEaV-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Abre el reporte y revisa cada una de las secciones:\n",
        "\n",
        "* **Detalles de ejecuci√≥n**: detalles sobre el algoritmo utilizado.\n",
        "* **Conjunto de Datos**: informaci√≥n sobre el conjunto de datos y las variables utilizadas.\n",
        "* **Hiperpar√°metros y configuraciones**: hiperpar√°metros seleccionados para la ejecuci√≥n del entrenamiento.\n",
        "* **Resultados**: m√©tricas de evaluaci√≥n para cada subconjunto de datos.\n",
        "* **Evoluci√≥n de entrenamiento**: gr√°ficas que muestran la evoluci√≥n de los valores de la funci√≥n de p√©rdida y la m√©trica de evaluaci√≥n a lo largo de las iteraciones.\n"
      ],
      "metadata": {
        "id": "4jOrvliYxBEP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y finalmente, dos secciones importantes para volver transparente el producto final del entrenamiento con machine learning:\n",
        "\n",
        "* **Muestreo de par√°metros durante entrenamiento**: aqu√≠ puedes ver c√≥mo cambiaron los valores de algunos par√°metros de tu modelo. Se inici√≥ con valores aleadorios y fueron modificados por el descenso de gradiente.\n"
      ],
      "metadata": {
        "id": "oI4fH29jx2yA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<center><img src=\"https://dialektico.com/wp-content/uploads/2025/08/DDG_report_2.png\" width=\"800\" /></center>"
      ],
      "metadata": {
        "id": "ridqHgngyPuQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y la √∫ltima secci√≥n:\n",
        "* **Modelo obtenido**: muestra la forma final del modelo que has entrenado y utilizas para hacer predicciones con datos nuevos.\n"
      ],
      "metadata": {
        "id": "gv5eiVFeytEo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<center><img src=\"https://dialektico.com/wp-content/uploads/2025/08/DDG_report_3.png\" width=\"800\" /></center>"
      ],
      "metadata": {
        "id": "MXBcsjmiy-jo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con estos reportes puedes observar los detalles matem√°ticos de tus modelos de aprendizaje autom√°tico, manteni√©ndote conectado con las t√©cnicas subyacentes que generan a la inteligencia artificial, y permitiendo compartir f√°cilmente res√∫menes de tu trabajo."
      ],
      "metadata": {
        "id": "dVTBjxoIzC7o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "MDGXl3FS0BZY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejecicio (opcional)"
      ],
      "metadata": {
        "id": "wu6h_mw-0Fd4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El ejercicio adicional es bastante sencillo. Modifica los hiperpar√°metros de entrenamiento para ver sus efectos en el rendimiento del modelo.\n",
        "\n",
        "El siguiente bloque entrena el modelo y genera el reporte de manera autom√°tica:"
      ],
      "metadata": {
        "id": "lWJT7aQM0R2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = methods.optimizer_archt(\"sgd-standard\",\n",
        "                                    learning_rate=0.05) # Tasa de aprendizaje.\n",
        "\n",
        "# Se entrena el modelo, seleccionando\n",
        "linreg = LinearRegressionArcht(\n",
        "    method     = \"batch\",\n",
        "    optimizer  = optimizer,\n",
        "    iterations = 50, # N√∫mero de iteraciones.\n",
        "    metric     = 'r2'\n",
        ")\n",
        "\n",
        "linreg.train(train_set);\n",
        "\n",
        "# Se utiliza el constructor de reportes, pasando el modelo y descripciones.\n",
        "builder = ReportBuilder(\n",
        "    mdl          = linreg,\n",
        "    dataset_name = dataset_description,\n",
        "    preprocessing = preprocessing_steps,\n",
        ")\n",
        "\n",
        "# Se genera el reporte.\n",
        "builder.to_html(\"reporte.html\")\n",
        "\n",
        "# Se descarga\n",
        "files.download(\"reporte.html\")\n",
        "print('\\nReporte generado y descargado.')"
      ],
      "metadata": {
        "id": "2ztBwmAM0KGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "c9LJTdAq0n4I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La pr√°ctica ha concluido aqu√≠. Has aplicado descenso de gradiente para ajustar los par√°metros de una ecuaci√≥n lineal, que permite estimar el precio de un viaje dado un conjunto de valores de variables."
      ],
      "metadata": {
        "id": "dPv9pJv8bTzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚ñ∂ [Regresar a la lecci√≥n](https://dialektico.com/descenso-de-gradiente/) üßô"
      ],
      "metadata": {
        "id": "ixgkHEdvbQVQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ap√©ndice"
      ],
      "metadata": {
        "id": "RFDjs55QEyym"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conjunto de datos"
      ],
      "metadata": {
        "id": "uQs1NNZJE7Zd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El conjunto de datos utilizado se obtuvo de Kaggle, sus detalles pueden ser consultados en la siguiente liga: https://www.kaggle.com/datasets/denkuznetz/taxi-price-prediction/data"
      ],
      "metadata": {
        "id": "Qx4YKGa2E9al"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dialektico Machine learning practices ¬© 2024 by Daniel Antonio Garc√≠a Escobar\n",
        "# is licensed under CC BY-NC 4.0. To view a copy of this license,\n",
        "# visit https://creativecommons.org/licenses/by-nc/4.0/\n",
        "\n",
        "# Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International\n",
        "# Public License"
      ],
      "metadata": {
        "id": "Z7vBuq0sbdDp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}