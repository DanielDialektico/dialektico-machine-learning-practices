{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPH8pWHGC2L/otegTkFdsi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanielDialektico/dialektico-machine-learning-practices/blob/main/notebooks/Machine%20Learning/Miscel%C3%A1nea/Sobreajuste_y_subajuste_de_modelos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://dialektico.com/wp-content/uploads/2023/03/MiniLogoW4.png\" alt=\"Dialéktico Logo\" />"
      ],
      "metadata": {
        "id": "RtNZWWNN_8rs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sobreajuste y subajuste de modelos de machine learning 👕**"
      ],
      "metadata": {
        "id": "Qa6aym27l3X0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Introducción**"
      ],
      "metadata": {
        "id": "diQbOuhrmGH2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "¿Cómo se comportan las predicciones de modelos **sobreajustados** y **subajustados**? En esta breve práctica visualizaremos cómo lucen los efectos de modelos de aprendizaje automático con ajustes deficientes, debido principalmente a la alta o poca dimensionalidad de sus mapeos, todo en concordancia con lo aprendido en el [recorrido en sobreajuste y subajuste de modelos](https://dialektico.com/subajuste-sobreajuste-teoria-programacion/).\n",
        "\n",
        "<br>\n",
        "<center><img src=\"https://dialektico.com/wp-content/uploads/2025/03/MSYS_Colab.png\" width=\"300\" /></center>"
      ],
      "metadata": {
        "id": "QUYZlI-wmJIu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "Dq-QqVAQ1iQV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Objetivo**"
      ],
      "metadata": {
        "id": "pLE-ED59cNMd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La meta es visualizar en **gráficas** cómo lucen los resultados de funciones **sobreajustadas** y **subajustadas** después de calcular sus **parámetros** mediante algoritmos de **aprendizaje automático**.\n",
        "\n",
        "<br>\n",
        "<center><img src=\"https://dialektico.com/wp-content/uploads/2025/03/MSYS_Colab_2.png\" width=\"400\" /></center>"
      ],
      "metadata": {
        "id": "_3Y_KtH_cOql"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "x_TR571C_bg7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Preparación de datos y librerías**"
      ],
      "metadata": {
        "id": "uAZfeqFxdBMz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comenzaremos por instalar e importar las librerías correspondientes, con las versiones específicas para procurar un correcto funcionamiento de la práctica:"
      ],
      "metadata": {
        "id": "RqeyW6wj_mR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se instalan las librerías.\n",
        "!pip install pandas==2.2.2\n",
        "!pip install matplotlib==3.10.0\n",
        "!pip install numpy==2.0.2\n",
        "!pip install scikit-learn==1.6.1\n",
        "\n",
        "# Se importan las librerías.\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Se filtran las advertencias.\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Se define el estilo de las gráficas.\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "\n",
        "# Se define el despliegue de flotantes en dataframes.\n",
        "pd.options.display.float_format = '{:.2f}'.format\n"
      ],
      "metadata": {
        "id": "TwmqO99bfCZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para esta práctica, nos es oportuno generar conjuntos de datos sintéticos (es decir, generados por nosotros, no recolectados), ya que buscamos simplificar la observación de los fenómenos de sobreajuste y subajuste en gráficas de dos dimensiones. Para esto, utilizaremos la librería [Numpy](https://numpy.org/):"
      ],
      "metadata": {
        "id": "BI7vjDS1AYNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se generan datos sintéticos con una relación no lineal.\n",
        "np.random.seed(42)\n",
        "X = np.sort(5 * np.random.rand(30, 1), axis=0)\n",
        "y = np.sin(X).ravel() + np.random.normal(0, 0.2, X.shape[0])"
      ],
      "metadata": {
        "id": "tBbKcReyiJFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "¿Qué hace este código?, genera los datos sintéticos que utilizaremos para ajustar modelos de machine learning, esto es lo que se hizo:\n",
        "\n",
        "\n",
        "\n",
        "* `np.random.seed(42)`: establece una semilla para el generador de números aleatorios de NumPy. Esto significa que cada vez que ejecutes el código, se obtendrán los mismos valores \"aleatorios\".\n",
        "* `np.random.rand(30, 1)`: genera una matriz de 30 filas y 1 columna con valores aleatorios entre 0 y 1. Luego se multiplica por 5, así que los valores estarán entre 0 y 5.\n",
        "* `np.sort(..., axis=0)`: ordena los valores de menor a mayor a lo largo del eje de las filas (eje 0).\n"
      ],
      "metadata": {
        "id": "tA5lU8O5iJph"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora imprimimos parte de la tabla con los datos:"
      ],
      "metadata": {
        "id": "AjrJbezHzgC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crea el DataFrame.\n",
        "df = pd.DataFrame(X, columns=[\"Variable de entrada\"])\n",
        "df[\"Variable objetivo (salida)\"] = y\n",
        "\n",
        "# Se muestran los primeros 10 valores de la tabla.\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "Psbl2Y5VyxI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estos datos que hemos creado, nos permiten imaginar cualquier escenario, ya que la información creada define una variable de **entrada** y una de **salida**, lo cual se puede ajustar a datos de diferentes fenómenos o situaciones.\n",
        "\n",
        "Veamos cómo lucen en una gráfica:"
      ],
      "metadata": {
        "id": "_bG10Qtw0E59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se genera la gráfica de dispersión de los puntos generados.\n",
        "plt.scatter(df[\"Variable de entrada\"], df[\"Variable objetivo (salida)\"],\n",
        "            color='blue', s=50, label='Datos')\n",
        "\n",
        "# Configuración del gráfico.\n",
        "plt.title(\"Dispersión de los datos\", fontsize=14, fontweight='bold')\n",
        "plt.xlabel(\"Variable de entrada 1\", fontsize=12, fontweight='bold')\n",
        "plt.ylabel(\"Variable objetivo\", fontsize=12, fontweight='bold')\n",
        "plt.legend(loc='upper right', fontsize=11)\n",
        "plt.grid(True)\n",
        "\n",
        "plt.suptitle(\"Figura 1: Distribución de los datos generados.\",\n",
        "             fontproperties={'family': 'DejaVu Sans', 'size': 11}, y=-0.001)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o6b6_FPa0Eol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora que tenemos los datos, buscaremos entrenar modelos que capturen su comportamiento."
      ],
      "metadata": {
        "id": "FEQ6OQAL1BUe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "GR5QN0L61Aam"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Entrenando un modelo con subajuste**"
      ],
      "metadata": {
        "id": "zB3p-5Tf1G--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora que tenemos un **conjunto de datos**, lo que queremos es obtener una **función** que describa su **tendencia**, para lo cual utilizaremos un algoritmo de aprendizaje supervisado, el cual será una **regresión linea**l.\n",
        "\n",
        "Para ilustrar cómo luce un modelo subajustado, utilizaremos una regresión lineal simple (univariable)."
      ],
      "metadata": {
        "id": "qd-vpIaG1PM-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src=\"https://dialektico.com/wp-content/uploads/2025/03/MSYS_K_1.jpg\" width=\"430\" /></center>"
      ],
      "metadata": {
        "id": "f36gBcYL5nTH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src=\"https://dialektico.com/wp-content/uploads/2025/03/MSYS_D_1.jpg\" width=\"430\" /></center>"
      ],
      "metadata": {
        "id": "Qud1xdzr9yLe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamos un modelo utilizando la regresión lineal con Scikit-Learn, la cual generará una función que trazará una línea recta que se intentará ajustar a los datos:"
      ],
      "metadata": {
        "id": "TQKr5aiDdh4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se dividen los datos en conjuntos de entrenamiento y prueba.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Se entrena un modelo con regresión lineal.\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train, y_train)\n",
        "y_pred_lin_train = lin_reg.predict(X_train)\n",
        "y_pred_lin_test = lin_reg.predict(X_test)\n",
        "\n",
        "# Se crea la gráfica.\n",
        "plt.figure(figsize=(6, 6))\n",
        "\n",
        "plt.plot(X, y, 'o', color='blue', markersize=6, label='Datos')\n",
        "\n",
        "x_range = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)\n",
        "y_line = lin_reg.predict(x_range)\n",
        "plt.plot(x_range, y_line, color='black', linewidth=2, label='Regresión lineal')\n",
        "\n",
        "# Configuración del gráfico\n",
        "plt.title(\"Modelado de datos con regresión lineal\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 16\n",
        "}, pad=15)\n",
        "plt.xlabel(\"Variable de entrada\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 12\n",
        "}, labelpad=15)\n",
        "plt.ylabel(\"Variable de salida\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 12\n",
        "}, labelpad=15)\n",
        "plt.legend(loc='upper right', prop={\n",
        "    'family': 'DejaVu Sans', 'weight': 'bold', 'size': 11\n",
        "}, frameon=True, framealpha=1, facecolor='#dddddd', shadow=True)\n",
        "\n",
        "plt.suptitle(\"Figura 2: Línea de regresión ajustada a los datos.\",\n",
        "             fontproperties={'family': 'DejaVu Sans', 'size': 11}, y=-0.001)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Cfd_G1OT-JmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notarás que se ha obtenido un **modelo** (ecuación de una recta) para la predicción de los datos.\n",
        "\n",
        "Para evaluar que tan bien actúa la función sobre los datos de prueba y entrenamiento, utilizaremos las métricas $\\text{MSE}$ (Error Cuadrático Medio) y $\\mathrm{R^2}$ (coeficiente de determinación):"
      ],
      "metadata": {
        "id": "1sOAKKlzDkhp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se calculan las métricas\n",
        "mse_lin_train = mean_squared_error(y_train, y_pred_lin_train)\n",
        "mse_lin_test = mean_squared_error(y_test, y_pred_lin_test)\n",
        "\n",
        "r2_train = lin_reg.score(X_train, y_train)\n",
        "r2_test = lin_reg.score(X_test, y_test)\n",
        "\n",
        "# Se imprimen.\n",
        "print(f\"MSE Entrenamiento: {mse_lin_train:.4f}\\nMSE Prueba: {mse_lin_test:.4f}\\n\")\n",
        "print(f\"R² Entrenamiento: {r2_train:.4f}\\nR² Prueba: {r2_test:.4f}\")"
      ],
      "metadata": {
        "id": "YZ3-qoH_-NvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "¿Recuerdas cómo interpretarlas? Puedes echar un vistazo a esta exploración: https://dialektico.com/metricas-de-evaluacion-de-modelos-de-regresion/\n"
      ],
      "metadata": {
        "id": "n7BukGfmE_DO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es hora de hacer un poco de **análisis de datos**; para interpretar el MSE necesitamos conocer los rangos de los datos de salida, para lo cual podemos utilizar la siguiente función de Pandas:"
      ],
      "metadata": {
        "id": "RTdL7pFOmZF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "oumehUVsl6us"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dado que los valores están entre $-0.99$ y $1.10$, se puede considerar que el punto medio se encuentra alrededor de $0$, por lo que las mediciones de $0.1924$ y $0.1873$ de MSE en los conjuntos de datos de entrenamiento y prueba se pueden considerar relativamente **altos**. Esto se ve reforzado por los valores calculados para $\\mathrm{R^2}$, los cuales están apenas por encima de $0.5$, indicando cierta lejanía del valor $1$, el cual sería el ideal para esta métrica.\n",
        "\n",
        "Vemos, por lo tanto, un **desempeño deficiente** al ser evaluado tanto en el conjunto de datos de **entrenamiento** como en el de **prueba**, lo cual indica que se tiene un modelo subajustado (además, la gráfica nos muestra una función claramente ineficiente para describir el **comportamiento** de las observaciones).\n",
        "\n"
      ],
      "metadata": {
        "id": "aQ4sYER4mh_r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "¿Cómo podemos mejorar el **ajuste** del **modelo**? Una de las formas más típicas es aumentando la **complejidad** del mismo, es decir, añadiendo un mayor número de **variables** regresoras parametrizadas del modelo final, como vimos en el ejemplo de modelos **subajustados** en nuestro recorrido.\n",
        "\n",
        "Para hacer esto, realizaremos otra regresión lineal, pero añadiendo variables no lineales al modelo final, permitiendo capturar comportamientos menos lineales.\n",
        "\n",
        "Esto se logra utilizando una **regresión polinomial** como se muestra a continuación:"
      ],
      "metadata": {
        "id": "Fej37qFAn0QU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se genera un modelo con mejor ajuste (Polinomio grado 3).\n",
        "poly_reg = make_pipeline(PolynomialFeatures(degree=3), LinearRegression())\n",
        "poly_reg.fit(X_train, y_train)\n",
        "X_plot = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)  # Generar puntos ordenados para una mejor visualización\n",
        "y_pred_poly_plot = poly_reg.predict(X_plot)\n",
        "\n",
        "# Se grafica.\n",
        "plt.figure(figsize=(6, 6))\n",
        "\n",
        "plt.plot(X, y, 'o', color='blue', markersize=6, label='Datos')\n",
        "\n",
        "plt.plot(X_plot, y_pred_poly_plot, color='black', linewidth=2, label='Regresión polinomial (grado 3)')\n",
        "\n",
        "# Configuración de la gráfica\n",
        "plt.title(\"Modelado de datos con regresión polinomial\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 16\n",
        "}, pad=15)\n",
        "plt.xlabel(\"Variable de entrada\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 12\n",
        "}, labelpad=15)\n",
        "plt.ylabel(\"Variable de salida\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 12\n",
        "}, labelpad=15)\n",
        "plt.legend(loc='upper right', prop={\n",
        "    'family': 'DejaVu Sans', 'weight': 'bold', 'size': 11\n",
        "}, frameon=True, framealpha=1, facecolor='#dddddd', shadow=True)\n",
        "\n",
        "plt.suptitle(\"Figura 3: Curva polinomial ajustada a los datos.\",\n",
        "             fontproperties={'family': 'DejaVu Sans', 'size': 11}, y=-0.001)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XqxG5CSZpD6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta segunda gráfica se observa un modelo mucho mejor ajustado a los datos. La diferencia es más visible si comparamos las gráficas directamente:"
      ],
      "metadata": {
        "id": "jdemLjJKthWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Graficamos la comparación entre el modelo subajustado y el mejor ajustado\n",
        "fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# ===== Subgráfico 1: Modelo subajustado =====\n",
        "axs[0].plot(X, y, 'o', color='blue', markersize=6, label='Datos')\n",
        "axs[0].plot(X_train, y_pred_lin_train, color='black', linewidth=2, label='Regresión lineal')\n",
        "axs[0].set_title(\"Modelado de datos con regresión lineal\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 16\n",
        "}, pad=15)\n",
        "axs[0].set_xlabel(\"Variable de entrada\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 12\n",
        "}, labelpad=15)\n",
        "axs[0].set_ylabel(\"Variable de salida\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 12\n",
        "}, labelpad=15)\n",
        "axs[0].legend(loc='upper right', prop={\n",
        "    'family': 'DejaVu Sans', 'weight': 'bold', 'size': 11\n",
        "}, frameon=True, framealpha=1, facecolor='#dddddd', shadow=True)\n",
        "axs[0].grid(True)\n",
        "\n",
        "# ===== Subgráfico 2: Modelo con mejor ajuste =====\n",
        "axs[1].plot(X, y, 'o', color='blue', markersize=6, label='Datos')\n",
        "axs[1].plot(X_plot, y_pred_poly_plot, color='black', linewidth=2, label='Regresión polinomial (grado 3)')\n",
        "axs[1].set_title(\"Modelado de datos con regresión polinomial\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 16\n",
        "}, pad=15)\n",
        "axs[1].set_xlabel(\"Variable de entrada\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 12\n",
        "}, labelpad=15)\n",
        "axs[1].set_ylabel(\"Variable de salida\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 12\n",
        "}, labelpad=15)\n",
        "axs[1].legend(loc='upper right', prop={\n",
        "    'family': 'DejaVu Sans', 'weight': 'bold', 'size': 11\n",
        "}, frameon=True, framealpha=1, facecolor='#dddddd', shadow=True)\n",
        "axs[1].grid(True)\n",
        "\n",
        "fig.suptitle(\"Figura 4: Comparación entre regresión lineal (subajustada) y polinomial (mejor ajuste).\",\n",
        "             fontproperties={'family': 'DejaVu Sans', 'size': 11}, y=0.02)\n",
        "\n",
        "plt.tight_layout(rect=[0, 0.04, 1, 1])  # Espacio para el subtítulo\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ViCR5en8thWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para obtener una medida analítica de estas diferencias, recurrimos a las métricas de desempeño:"
      ],
      "metadata": {
        "id": "Q4VbwBzxthWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se calculan errores para la nueva función.\n",
        "mse_poly_train = mean_squared_error(y_train, poly_reg.predict(X_train))\n",
        "mse_poly_test = mean_squared_error(y_test, poly_reg.predict(X_test))\n",
        "\n",
        "poly_r2_train = poly_reg.score(X_train, y_train)\n",
        "poly_r2_test = poly_reg.score(X_test, y_test)\n",
        "\n",
        "# Se imprimen.\n",
        "print('Métricas de evaluación del modelo polinomial con mejor ajuste:\\n')\n",
        "print(f\"MSE Entrenamiento: {mse_poly_train:.4f}\\nMSE Prueba: {mse_poly_test:.4f}\\n\")\n",
        "print(f\"R² Entrenamiento: {poly_r2_train:.4f}\\nR² Prueba: {poly_r2_test:.4f}\")"
      ],
      "metadata": {
        "id": "6K1BCFY9o8kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es muy notoria la diferencia con las métricas obtenidas para el modelo subajustad, la cual se puede discernir mejor en la siguiente tabla:"
      ],
      "metadata": {
        "id": "RUHZmWfBqTU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear DataFrame comparativo\n",
        "df_metrics = pd.DataFrame({\n",
        "    \"Modelo subajustado\": [mse_lin_train, mse_lin_test, r2_train, r2_test],\n",
        "    \"Modelo con mejor ajuste\": [mse_poly_train, mse_poly_test, poly_r2_train, poly_r2_test]\n",
        "}, index=[\"MSE Entrenamiento\", \"MSE Prueba\", \"R² Entrenamiento\", \"R² Prueba\"])\n",
        "\n",
        "# Mostrar la tabla\n",
        "df_metrics"
      ],
      "metadata": {
        "id": "vGgEgmupqrOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos observar cómo el $\\mathrm{R^2}$ se acerca casi al $1$ ideal en el modelo polinomial (con mejor ajuste), además de que el MSE es más del doble del obtenido en el modelo **subajustado**. Las métricas obtenidas para el modelo con mejor ajuste arrojan resultados parecidos para los conjuntos de entrenamiento y prueba, lo cual suele indicar un modelo \"saludable\" en sus predicciones, es decir, con una aceptable capacidad de generalización sobre datos nuevos."
      ],
      "metadata": {
        "id": "7fSEJkzdrDY_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src=\"https://dialektico.com/wp-content/uploads/2025/03/MSYS_M_1.jpg\" width=\"500\" /></center>"
      ],
      "metadata": {
        "id": "_0ti5OoxqNwE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "VlKFiKmjr9VE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Entrenando un modelo sobreajustado**"
      ],
      "metadata": {
        "id": "NbJxqCpYr9fF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hemos visto cómo lucen las predicciones de un modelo **subajustado**, por lo que sigue experimentar con un modelo **sobreajustado** a las observaciones.\n",
        "\n",
        "Para esto, utilizaremos el mismo conjunto de datos, pero incrementando la complejidad del modelo con un polinomio de mayor grado (grado 15):"
      ],
      "metadata": {
        "id": "tOv1L0Yfr9fF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se genera modelo sobreajustado (Polinomio grado 15).\n",
        "poly_reg_overfit = make_pipeline(PolynomialFeatures(degree=15), LinearRegression())\n",
        "poly_reg_overfit.fit(X_train, y_train)\n",
        "\n",
        "X_plot = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)  # Generar puntos ordenados para una mejor visualización\n",
        "y_pred_poly_plot = poly_reg_overfit.predict(X_plot)\n",
        "\n",
        "# Se grafican los resultados.\n",
        "plt.figure(figsize=(6, 6))\n",
        "\n",
        "plt.plot(X, y, 'o', color='blue', markersize=6, label='Datos')\n",
        "\n",
        "plt.plot(X_plot, y_pred_poly_plot, color='black', linewidth=2, label='Regresión polinomial (grado 15)')\n",
        "\n",
        "# Configuración de la gráfica\n",
        "plt.title(\"Modelado de datos sobreajustado\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 16\n",
        "}, pad=15)\n",
        "plt.xlabel(\"Variable de entrada\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 12\n",
        "}, labelpad=15)\n",
        "plt.ylabel(\"Variable de salida\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 12\n",
        "}, labelpad=15)\n",
        "plt.legend(loc='lower left', prop={\n",
        "    'family': 'DejaVu Sans', 'weight': 'bold', 'size': 11\n",
        "}, frameon=True, framealpha=1, facecolor='#dddddd', shadow=True)\n",
        "\n",
        "plt.suptitle(\"Figura 5: Curva polinomial ajustada a los datos.\",\n",
        "             fontproperties={'family': 'DejaVu Sans', 'size': 11}, y=-0.001)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NBF-zmPKr9fG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos observar al mismo conjunto de datos, pero con un modelo aún más ajustado que el anterior, adhiriéndose al comportamiento exacto de la muestra.\n",
        "\n",
        "Este modelo se estaría **sesgando** por su alta fidelidad a las **variaciones** de los datos, que no reflejan el **patrón** que se ha supuesto que subyace a su tendencia.\n",
        "\n",
        "Obtenemos las métricas de evaluación para medir su desempeño:"
      ],
      "metadata": {
        "id": "HCD8EteQr9fG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se calculan los errores.\n",
        "mse_poly15_train = mean_squared_error(y_train, poly_reg_overfit.predict(X_train))\n",
        "mse_poly15_test = mean_squared_error(y_test, poly_reg_overfit.predict(X_test))\n",
        "\n",
        "poly15_r2_train = poly_reg_overfit.score(X_train, y_train)\n",
        "poly15_r2_test = poly_reg_overfit.score(X_test, y_test)\n",
        "\n",
        "# Se imprimen.\n",
        "print(f\"MSE Entrenamiento: {mse_poly15_train:.4f}\\nMSE Prueba: {mse_poly15_test:.4f}\\n\")\n",
        "print(f\"R² Entrenamiento: {poly15_r2_train:.4f}\\nR² Prueba: {poly15_r2_test:.4f}\")"
      ],
      "metadata": {
        "id": "XB2Odq6Zr9fG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se puede notar la diferencia entre los resultados sobre el conjunto de datos de entrenamiento y el de prueba.\n",
        "\n",
        "La comparación final luciría de la siguiente manera:"
      ],
      "metadata": {
        "id": "AYPqVbi6yIpW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crea DataFrame comparativo.\n",
        "df_metrics = pd.DataFrame({\n",
        "    \"Modelo subajustado\": [mse_lin_train, mse_lin_test, r2_train, r2_test],\n",
        "    \"Modelo con mejor ajuste\": [mse_poly_train, mse_poly_test, poly_r2_train, poly_r2_test],\n",
        "    \"Modelo sobreajustado\": [mse_poly15_train, mse_poly15_test, poly15_r2_train, poly15_r2_test]\n",
        "}, index=[\"MSE Entrenamiento\", \"MSE Prueba\", \"R² Entrenamiento\", \"R² Prueba\"])\n",
        "\n",
        "# Se imprime.\n",
        "df_metrics"
      ],
      "metadata": {
        "id": "S5Nt_l6Vr9fH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo con mejor ajuste muestra valores aceptables y parecidos para ambos conjuntos de datos.\n",
        "\n",
        "El modelo **subajustado** mantiene métricas deficientes para ambos conjuntos, mientras que el modelo **sobreajustado** difiere de forma significativa en las medidas entre ambos conjuntos."
      ],
      "metadata": {
        "id": "ju7CuOMsyL-t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente, mostramos cómo lucen los tres modelos entrenados en esta sesión:"
      ],
      "metadata": {
        "id": "xMr1acEgzBud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rrangos de valores para las predicciones de cada modelo\n",
        "x_range = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)  # Para el modelo lineal\n",
        "X_plot_poly = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)  # Para el polinomio grado 3\n",
        "X_plot_overfit = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)  # Para el polinomio grado 15\n",
        "\n",
        "# Predicciones de cada modelo\n",
        "y_line = lin_reg.predict(x_range)\n",
        "y_pred_poly = poly_reg.predict(X_plot_poly)\n",
        "y_pred_poly_overfit = poly_reg_overfit.predict(X_plot_overfit)\n",
        "\n",
        "# Figura con tres subgráficas\n",
        "fig, axs = plt.subplots(1, 3, figsize=(21, 6))\n",
        "\n",
        "# ----- Subgráfico 1: Modelo subajustado (Regresión lineal) -----\n",
        "axs[0].plot(X, y, 'o', color='blue', markersize=6, label='Datos')\n",
        "axs[0].plot(x_range, y_line, color='black', linewidth=2, label='Regresión lineal')\n",
        "axs[0].set_title(\"Modelado de datos con regresión lineal (subajuste)\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 16\n",
        "}, pad=15)\n",
        "axs[0].set_xlabel(\"Variable de entrada\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 12\n",
        "}, labelpad=15)\n",
        "axs[0].set_ylabel(\"Variable de salida\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 12\n",
        "}, labelpad=15)\n",
        "axs[0].legend(loc='upper right', prop={\n",
        "    'family': 'DejaVu Sans', 'weight': 'bold', 'size': 11\n",
        "}, frameon=True, framealpha=1, facecolor='#dddddd', shadow=True)\n",
        "axs[0].grid(True)\n",
        "\n",
        "# ----- Subgráfico 2: Modelo con mejor ajuste (Polinomio grado 3) -----\n",
        "axs[1].plot(X, y, 'o', color='blue', markersize=6, label='Datos')\n",
        "axs[1].plot(X_plot_poly, y_pred_poly, color='black', linewidth=2, label='Regresión polinomial (grado 3)')\n",
        "axs[1].set_title(\"Modelado de datos con regresión polinomial\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 16\n",
        "}, pad=15)\n",
        "axs[1].set_xlabel(\"Variable de entrada\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 12\n",
        "}, labelpad=15)\n",
        "axs[1].set_ylabel(\"Variable de salida\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 12\n",
        "}, labelpad=15)\n",
        "axs[1].legend(loc='upper right', prop={\n",
        "    'family': 'DejaVu Sans', 'weight': 'bold', 'size': 11\n",
        "}, frameon=True, framealpha=1, facecolor='#dddddd', shadow=True)\n",
        "axs[1].grid(True)\n",
        "\n",
        "# ----- Subgráfico 3: Modelo sobreajustado (Polinomio grado 15) -----\n",
        "axs[2].plot(X, y, 'o', color='blue', markersize=6, label='Datos')\n",
        "axs[2].plot(X_plot_overfit, y_pred_poly_overfit, color='black', linewidth=2, label='Regresión polinomial (grado 15)')\n",
        "axs[2].set_title(\"Modelado de datos con regresión polinomial (sobreajuste)\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 16\n",
        "}, pad=15)\n",
        "axs[2].set_xlabel(\"Variable de entrada\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 12\n",
        "}, labelpad=15)\n",
        "axs[2].set_ylabel(\"Variable de salida\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 12\n",
        "}, labelpad=15)\n",
        "axs[2].legend(loc='lower left', prop={\n",
        "    'family': 'DejaVu Sans', 'weight': 'bold', 'size': 11\n",
        "}, frameon=True, framealpha=1, facecolor='#dddddd', shadow=True)\n",
        "axs[2].grid(True)\n",
        "\n",
        "fig.suptitle(\"Fig. 4 Comparación entre regresión lineal (subajustada) y polinomial (mejor ajuste).\",\n",
        "             fontproperties={'family': 'DejaVu Sans', 'size': 11}, y=0.01)\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3E5YnRhksznV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "WNnVFnSMdKRb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hemos terminado nuestra práctica en modelos **sobreajustados** y **subajustados**. Hemos **entrenado** y **evaluado** diferentes modelos con deficiencias en el ajuste de sus parámetros, y visualizado sus diferencias claves en gráficas y métricas de evaluación."
      ],
      "metadata": {
        "id": "GOyqpx_OdLpD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "▶ [Regresar a la lección](https://dialektico.com/subajuste-sobreajuste-teoria-programacion/) 🧙"
      ],
      "metadata": {
        "id": "G8YVS38T9h4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dialektico Machine learning practices © 2025 by Daniel Antonio García Escobar\n",
        "# is licensed under CC BY-NC 4.0. To view a copy of this license,\n",
        "# visit https://creativecommons.org/licenses/by-nc/4.0/\n",
        "\n",
        "# Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International\n",
        "# Public License"
      ],
      "metadata": {
        "id": "mC5uisEVNodI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}