{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPH8pWHGC2L/otegTkFdsi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanielDialektico/dialektico-machine-learning-practices/blob/main/notebooks/Machine%20Learning/Miscel%C3%A1nea/Sobreajuste_y_subajuste_de_modelos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://dialektico.com/wp-content/uploads/2023/03/MiniLogoW4.png\" alt=\"Dial√©ktico Logo\" />"
      ],
      "metadata": {
        "id": "RtNZWWNN_8rs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sobreajuste y subajuste de modelos de machine learning üëï**"
      ],
      "metadata": {
        "id": "Qa6aym27l3X0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Introducci√≥n**"
      ],
      "metadata": {
        "id": "diQbOuhrmGH2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "¬øC√≥mo se comportan las predicciones de modelos **sobreajustados** y **subajustados**? En esta breve pr√°ctica visualizaremos c√≥mo lucen los efectos de modelos de aprendizaje autom√°tico con ajustes deficientes, debido principalmente a la alta o poca dimensionalidad de sus mapeos, todo en concordancia con lo aprendido en el [recorrido en sobreajuste y subajuste de modelos](https://dialektico.com/subajuste-sobreajuste-teoria-programacion/).\n",
        "\n",
        "<br>\n",
        "<center><img src=\"https://dialektico.com/wp-content/uploads/2025/03/MSYS_Colab.png\" width=\"300\" /></center>"
      ],
      "metadata": {
        "id": "QUYZlI-wmJIu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "Dq-QqVAQ1iQV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Objetivo**"
      ],
      "metadata": {
        "id": "pLE-ED59cNMd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La meta es visualizar en **gr√°ficas** c√≥mo lucen los resultados de funciones **sobreajustadas** y **subajustadas** despu√©s de calcular sus **par√°metros** mediante algoritmos de **aprendizaje autom√°tico**.\n",
        "\n",
        "<br>\n",
        "<center><img src=\"https://dialektico.com/wp-content/uploads/2025/03/MSYS_Colab_2.png\" width=\"400\" /></center>"
      ],
      "metadata": {
        "id": "_3Y_KtH_cOql"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "x_TR571C_bg7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Preparaci√≥n de datos y librer√≠as**"
      ],
      "metadata": {
        "id": "uAZfeqFxdBMz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comenzaremos por instalar e importar las librer√≠as correspondientes, con las versiones espec√≠ficas para procurar un correcto funcionamiento de la pr√°ctica:"
      ],
      "metadata": {
        "id": "RqeyW6wj_mR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se instalan las librer√≠as.\n",
        "!pip install pandas==2.2.2\n",
        "!pip install matplotlib==3.10.0\n",
        "!pip install numpy==2.0.2\n",
        "!pip install scikit-learn==1.6.1\n",
        "\n",
        "# Se importan las librer√≠as.\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Se filtran las advertencias.\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Se define el estilo de las gr√°ficas.\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "\n",
        "# Se define el despliegue de flotantes en dataframes.\n",
        "pd.options.display.float_format = '{:.2f}'.format\n"
      ],
      "metadata": {
        "id": "TwmqO99bfCZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para esta pr√°ctica, nos es oportuno generar conjuntos de datos sint√©ticos (es decir, generados por nosotros, no recolectados), ya que buscamos simplificar la observaci√≥n de los fen√≥menos de sobreajuste y subajuste en gr√°ficas de dos dimensiones. Para esto, utilizaremos la librer√≠a [Numpy](https://numpy.org/):"
      ],
      "metadata": {
        "id": "BI7vjDS1AYNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se generan datos sint√©ticos con una relaci√≥n no lineal.\n",
        "np.random.seed(42)\n",
        "X = np.sort(5 * np.random.rand(30, 1), axis=0)\n",
        "y = np.sin(X).ravel() + np.random.normal(0, 0.2, X.shape[0])"
      ],
      "metadata": {
        "id": "tBbKcReyiJFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "¬øQu√© hace este c√≥digo?, genera los datos sint√©ticos que utilizaremos para ajustar modelos de machine learning, esto es lo que se hizo:\n",
        "\n",
        "\n",
        "\n",
        "* `np.random.seed(42)`: establece una semilla para el generador de n√∫meros aleatorios de NumPy. Esto significa que cada vez que ejecutes el c√≥digo, se obtendr√°n los mismos valores \"aleatorios\".\n",
        "* `np.random.rand(30, 1)`: genera una matriz de 30 filas y 1 columna con valores aleatorios entre 0 y 1. Luego se multiplica por 5, as√≠ que los valores estar√°n entre 0 y 5.\n",
        "* `np.sort(..., axis=0)`: ordena los valores de menor a mayor a lo largo del eje de las filas (eje 0).\n"
      ],
      "metadata": {
        "id": "tA5lU8O5iJph"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora imprimimos parte de la tabla con los datos:"
      ],
      "metadata": {
        "id": "AjrJbezHzgC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crea el DataFrame.\n",
        "df = pd.DataFrame(X, columns=[\"Variable de entrada\"])\n",
        "df[\"Variable objetivo (salida)\"] = y\n",
        "\n",
        "# Se muestran los primeros 10 valores de la tabla.\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "Psbl2Y5VyxI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estos datos que hemos creado, nos permiten imaginar cualquier escenario, ya que la informaci√≥n creada define una variable de **entrada** y una de **salida**, lo cual se puede ajustar a datos de diferentes fen√≥menos o situaciones.\n",
        "\n",
        "Veamos c√≥mo lucen en una gr√°fica:"
      ],
      "metadata": {
        "id": "_bG10Qtw0E59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se genera la gr√°fica de dispersi√≥n de los puntos generados.\n",
        "plt.scatter(df[\"Variable de entrada\"], df[\"Variable objetivo (salida)\"],\n",
        "            color='blue', s=50, label='Datos')\n",
        "\n",
        "# Configuraci√≥n del gr√°fico.\n",
        "plt.title(\"Dispersi√≥n de los datos\", fontsize=14, fontweight='bold')\n",
        "plt.xlabel(\"Variable de entrada 1\", fontsize=12, fontweight='bold')\n",
        "plt.ylabel(\"Variable objetivo\", fontsize=12, fontweight='bold')\n",
        "plt.legend(loc='upper right', fontsize=11)\n",
        "plt.grid(True)\n",
        "\n",
        "plt.suptitle(\"Figura 1: Distribuci√≥n de los datos generados.\",\n",
        "             fontproperties={'family': 'DejaVu Sans', 'size': 11}, y=-0.001)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o6b6_FPa0Eol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora que tenemos los datos, buscaremos entrenar modelos que capturen su comportamiento."
      ],
      "metadata": {
        "id": "FEQ6OQAL1BUe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "GR5QN0L61Aam"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Entrenando un modelo con subajuste**"
      ],
      "metadata": {
        "id": "zB3p-5Tf1G--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora que tenemos un **conjunto de datos**, lo que queremos es obtener una **funci√≥n** que describa su **tendencia**, para lo cual utilizaremos un algoritmo de aprendizaje supervisado, el cual ser√° una **regresi√≥n linea**l.\n",
        "\n",
        "Para ilustrar c√≥mo luce un modelo subajustado, utilizaremos una regresi√≥n lineal simple (univariable)."
      ],
      "metadata": {
        "id": "qd-vpIaG1PM-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src=\"https://dialektico.com/wp-content/uploads/2025/03/MSYS_K_1.jpg\" width=\"430\" /></center>"
      ],
      "metadata": {
        "id": "f36gBcYL5nTH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src=\"https://dialektico.com/wp-content/uploads/2025/03/MSYS_D_1.jpg\" width=\"430\" /></center>"
      ],
      "metadata": {
        "id": "Qud1xdzr9yLe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamos un modelo utilizando la regresi√≥n lineal con Scikit-Learn, la cual generar√° una funci√≥n que trazar√° una l√≠nea recta que se intentar√° ajustar a los datos:"
      ],
      "metadata": {
        "id": "TQKr5aiDdh4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se dividen los datos en conjuntos de entrenamiento y prueba.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Se entrena un modelo con regresi√≥n lineal.\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train, y_train)\n",
        "y_pred_lin_train = lin_reg.predict(X_train)\n",
        "y_pred_lin_test = lin_reg.predict(X_test)\n",
        "\n",
        "# Se crea la gr√°fica.\n",
        "plt.figure(figsize=(6, 6))\n",
        "\n",
        "plt.plot(X, y, 'o', color='blue', markersize=6, label='Datos')\n",
        "\n",
        "x_range = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)\n",
        "y_line = lin_reg.predict(x_range)\n",
        "plt.plot(x_range, y_line, color='black', linewidth=2, label='Regresi√≥n lineal')\n",
        "\n",
        "# Configuraci√≥n del gr√°fico\n",
        "plt.title(\"Modelado de datos con regresi√≥n lineal\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 16\n",
        "}, pad=15)\n",
        "plt.xlabel(\"Variable de entrada\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 12\n",
        "}, labelpad=15)\n",
        "plt.ylabel(\"Variable de salida\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 12\n",
        "}, labelpad=15)\n",
        "plt.legend(loc='upper right', prop={\n",
        "    'family': 'DejaVu Sans', 'weight': 'bold', 'size': 11\n",
        "}, frameon=True, framealpha=1, facecolor='#dddddd', shadow=True)\n",
        "\n",
        "plt.suptitle(\"Figura 2: L√≠nea de regresi√≥n ajustada a los datos.\",\n",
        "             fontproperties={'family': 'DejaVu Sans', 'size': 11}, y=-0.001)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Cfd_G1OT-JmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notar√°s que se ha obtenido un **modelo** (ecuaci√≥n de una recta) para la predicci√≥n de los datos.\n",
        "\n",
        "Para evaluar que tan bien act√∫a la funci√≥n sobre los datos de prueba y entrenamiento, utilizaremos las m√©tricas $\\text{MSE}$ (Error Cuadr√°tico Medio) y $\\mathrm{R^2}$ (coeficiente de determinaci√≥n):"
      ],
      "metadata": {
        "id": "1sOAKKlzDkhp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se calculan las m√©tricas\n",
        "mse_lin_train = mean_squared_error(y_train, y_pred_lin_train)\n",
        "mse_lin_test = mean_squared_error(y_test, y_pred_lin_test)\n",
        "\n",
        "r2_train = lin_reg.score(X_train, y_train)\n",
        "r2_test = lin_reg.score(X_test, y_test)\n",
        "\n",
        "# Se imprimen.\n",
        "print(f\"MSE Entrenamiento: {mse_lin_train:.4f}\\nMSE Prueba: {mse_lin_test:.4f}\\n\")\n",
        "print(f\"R¬≤ Entrenamiento: {r2_train:.4f}\\nR¬≤ Prueba: {r2_test:.4f}\")"
      ],
      "metadata": {
        "id": "YZ3-qoH_-NvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "¬øRecuerdas c√≥mo interpretarlas? Puedes echar un vistazo a esta exploraci√≥n: https://dialektico.com/metricas-de-evaluacion-de-modelos-de-regresion/\n"
      ],
      "metadata": {
        "id": "n7BukGfmE_DO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es hora de hacer un poco de **an√°lisis de datos**; para interpretar el MSE necesitamos conocer los rangos de los datos de salida, para lo cual podemos utilizar la siguiente funci√≥n de Pandas:"
      ],
      "metadata": {
        "id": "RTdL7pFOmZF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "oumehUVsl6us"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dado que los valores est√°n entre $-0.99$ y $1.10$, se puede considerar que el punto medio se encuentra alrededor de $0$, por lo que las mediciones de $0.1924$ y $0.1873$ de MSE en los conjuntos de datos de entrenamiento y prueba se pueden considerar relativamente **altos**. Esto se ve reforzado por los valores calculados para $\\mathrm{R^2}$, los cuales est√°n apenas por encima de $0.5$, indicando cierta lejan√≠a del valor $1$, el cual ser√≠a el ideal para esta m√©trica.\n",
        "\n",
        "Vemos, por lo tanto, un **desempe√±o deficiente** al ser evaluado tanto en el conjunto de datos de **entrenamiento** como en el de **prueba**, lo cual indica que se tiene un modelo subajustado (adem√°s, la gr√°fica nos muestra una funci√≥n claramente ineficiente para describir el **comportamiento** de las observaciones).\n",
        "\n"
      ],
      "metadata": {
        "id": "aQ4sYER4mh_r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "¬øC√≥mo podemos mejorar el **ajuste** del **modelo**? Una de las formas m√°s t√≠picas es aumentando la **complejidad** del mismo, es decir, a√±adiendo un mayor n√∫mero de **variables** regresoras parametrizadas del modelo final, como vimos en el ejemplo de modelos **subajustados** en nuestro recorrido.\n",
        "\n",
        "Para hacer esto, realizaremos otra regresi√≥n lineal, pero a√±adiendo variables no lineales al modelo final, permitiendo capturar comportamientos menos lineales.\n",
        "\n",
        "Esto se logra utilizando una **regresi√≥n polinomial** como se muestra a continuaci√≥n:"
      ],
      "metadata": {
        "id": "Fej37qFAn0QU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se genera un modelo con mejor ajuste (Polinomio grado 3).\n",
        "poly_reg = make_pipeline(PolynomialFeatures(degree=3), LinearRegression())\n",
        "poly_reg.fit(X_train, y_train)\n",
        "X_plot = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)  # Generar puntos ordenados para una mejor visualizaci√≥n\n",
        "y_pred_poly_plot = poly_reg.predict(X_plot)\n",
        "\n",
        "# Se grafica.\n",
        "plt.figure(figsize=(6, 6))\n",
        "\n",
        "plt.plot(X, y, 'o', color='blue', markersize=6, label='Datos')\n",
        "\n",
        "plt.plot(X_plot, y_pred_poly_plot, color='black', linewidth=2, label='Regresi√≥n polinomial (grado 3)')\n",
        "\n",
        "# Configuraci√≥n de la gr√°fica\n",
        "plt.title(\"Modelado de datos con regresi√≥n polinomial\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 16\n",
        "}, pad=15)\n",
        "plt.xlabel(\"Variable de entrada\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 12\n",
        "}, labelpad=15)\n",
        "plt.ylabel(\"Variable de salida\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 12\n",
        "}, labelpad=15)\n",
        "plt.legend(loc='upper right', prop={\n",
        "    'family': 'DejaVu Sans', 'weight': 'bold', 'size': 11\n",
        "}, frameon=True, framealpha=1, facecolor='#dddddd', shadow=True)\n",
        "\n",
        "plt.suptitle(\"Figura 3: Curva polinomial ajustada a los datos.\",\n",
        "             fontproperties={'family': 'DejaVu Sans', 'size': 11}, y=-0.001)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XqxG5CSZpD6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta segunda gr√°fica se observa un modelo mucho mejor ajustado a los datos. La diferencia es m√°s visible si comparamos las gr√°ficas directamente:"
      ],
      "metadata": {
        "id": "jdemLjJKthWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Graficamos la comparaci√≥n entre el modelo subajustado y el mejor ajustado\n",
        "fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# ===== Subgr√°fico 1: Modelo subajustado =====\n",
        "axs[0].plot(X, y, 'o', color='blue', markersize=6, label='Datos')\n",
        "axs[0].plot(X_train, y_pred_lin_train, color='black', linewidth=2, label='Regresi√≥n lineal')\n",
        "axs[0].set_title(\"Modelado de datos con regresi√≥n lineal\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 16\n",
        "}, pad=15)\n",
        "axs[0].set_xlabel(\"Variable de entrada\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 12\n",
        "}, labelpad=15)\n",
        "axs[0].set_ylabel(\"Variable de salida\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 12\n",
        "}, labelpad=15)\n",
        "axs[0].legend(loc='upper right', prop={\n",
        "    'family': 'DejaVu Sans', 'weight': 'bold', 'size': 11\n",
        "}, frameon=True, framealpha=1, facecolor='#dddddd', shadow=True)\n",
        "axs[0].grid(True)\n",
        "\n",
        "# ===== Subgr√°fico 2: Modelo con mejor ajuste =====\n",
        "axs[1].plot(X, y, 'o', color='blue', markersize=6, label='Datos')\n",
        "axs[1].plot(X_plot, y_pred_poly_plot, color='black', linewidth=2, label='Regresi√≥n polinomial (grado 3)')\n",
        "axs[1].set_title(\"Modelado de datos con regresi√≥n polinomial\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 16\n",
        "}, pad=15)\n",
        "axs[1].set_xlabel(\"Variable de entrada\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 12\n",
        "}, labelpad=15)\n",
        "axs[1].set_ylabel(\"Variable de salida\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 12\n",
        "}, labelpad=15)\n",
        "axs[1].legend(loc='upper right', prop={\n",
        "    'family': 'DejaVu Sans', 'weight': 'bold', 'size': 11\n",
        "}, frameon=True, framealpha=1, facecolor='#dddddd', shadow=True)\n",
        "axs[1].grid(True)\n",
        "\n",
        "fig.suptitle(\"Figura 4: Comparaci√≥n entre regresi√≥n lineal (subajustada) y polinomial (mejor ajuste).\",\n",
        "             fontproperties={'family': 'DejaVu Sans', 'size': 11}, y=0.02)\n",
        "\n",
        "plt.tight_layout(rect=[0, 0.04, 1, 1])  # Espacio para el subt√≠tulo\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ViCR5en8thWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para obtener una medida anal√≠tica de estas diferencias, recurrimos a las m√©tricas de desempe√±o:"
      ],
      "metadata": {
        "id": "Q4VbwBzxthWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se calculan errores para la nueva funci√≥n.\n",
        "mse_poly_train = mean_squared_error(y_train, poly_reg.predict(X_train))\n",
        "mse_poly_test = mean_squared_error(y_test, poly_reg.predict(X_test))\n",
        "\n",
        "poly_r2_train = poly_reg.score(X_train, y_train)\n",
        "poly_r2_test = poly_reg.score(X_test, y_test)\n",
        "\n",
        "# Se imprimen.\n",
        "print('M√©tricas de evaluaci√≥n del modelo polinomial con mejor ajuste:\\n')\n",
        "print(f\"MSE Entrenamiento: {mse_poly_train:.4f}\\nMSE Prueba: {mse_poly_test:.4f}\\n\")\n",
        "print(f\"R¬≤ Entrenamiento: {poly_r2_train:.4f}\\nR¬≤ Prueba: {poly_r2_test:.4f}\")"
      ],
      "metadata": {
        "id": "6K1BCFY9o8kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es muy notoria la diferencia con las m√©tricas obtenidas para el modelo subajustad, la cual se puede discernir mejor en la siguiente tabla:"
      ],
      "metadata": {
        "id": "RUHZmWfBqTU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear DataFrame comparativo\n",
        "df_metrics = pd.DataFrame({\n",
        "    \"Modelo subajustado\": [mse_lin_train, mse_lin_test, r2_train, r2_test],\n",
        "    \"Modelo con mejor ajuste\": [mse_poly_train, mse_poly_test, poly_r2_train, poly_r2_test]\n",
        "}, index=[\"MSE Entrenamiento\", \"MSE Prueba\", \"R¬≤ Entrenamiento\", \"R¬≤ Prueba\"])\n",
        "\n",
        "# Mostrar la tabla\n",
        "df_metrics"
      ],
      "metadata": {
        "id": "vGgEgmupqrOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos observar c√≥mo el $\\mathrm{R^2}$ se acerca casi al $1$ ideal en el modelo polinomial (con mejor ajuste), adem√°s de que el MSE es m√°s del doble del obtenido en el modelo **subajustado**. Las m√©tricas obtenidas para el modelo con mejor ajuste arrojan resultados parecidos para los conjuntos de entrenamiento y prueba, lo cual suele indicar un modelo \"saludable\" en sus predicciones, es decir, con una aceptable capacidad de generalizaci√≥n sobre datos nuevos."
      ],
      "metadata": {
        "id": "7fSEJkzdrDY_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src=\"https://dialektico.com/wp-content/uploads/2025/03/MSYS_M_1.jpg\" width=\"500\" /></center>"
      ],
      "metadata": {
        "id": "_0ti5OoxqNwE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "VlKFiKmjr9VE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Entrenando un modelo sobreajustado**"
      ],
      "metadata": {
        "id": "NbJxqCpYr9fF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hemos visto c√≥mo lucen las predicciones de un modelo **subajustado**, por lo que sigue experimentar con un modelo **sobreajustado** a las observaciones.\n",
        "\n",
        "Para esto, utilizaremos el mismo conjunto de datos, pero incrementando la complejidad del modelo con un polinomio de mayor grado (grado 15):"
      ],
      "metadata": {
        "id": "tOv1L0Yfr9fF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se genera modelo sobreajustado (Polinomio grado 15).\n",
        "poly_reg_overfit = make_pipeline(PolynomialFeatures(degree=15), LinearRegression())\n",
        "poly_reg_overfit.fit(X_train, y_train)\n",
        "\n",
        "X_plot = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)  # Generar puntos ordenados para una mejor visualizaci√≥n\n",
        "y_pred_poly_plot = poly_reg_overfit.predict(X_plot)\n",
        "\n",
        "# Se grafican los resultados.\n",
        "plt.figure(figsize=(6, 6))\n",
        "\n",
        "plt.plot(X, y, 'o', color='blue', markersize=6, label='Datos')\n",
        "\n",
        "plt.plot(X_plot, y_pred_poly_plot, color='black', linewidth=2, label='Regresi√≥n polinomial (grado 15)')\n",
        "\n",
        "# Configuraci√≥n de la gr√°fica\n",
        "plt.title(\"Modelado de datos sobreajustado\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 16\n",
        "}, pad=15)\n",
        "plt.xlabel(\"Variable de entrada\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 12\n",
        "}, labelpad=15)\n",
        "plt.ylabel(\"Variable de salida\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 12\n",
        "}, labelpad=15)\n",
        "plt.legend(loc='lower left', prop={\n",
        "    'family': 'DejaVu Sans', 'weight': 'bold', 'size': 11\n",
        "}, frameon=True, framealpha=1, facecolor='#dddddd', shadow=True)\n",
        "\n",
        "plt.suptitle(\"Figura 5: Curva polinomial ajustada a los datos.\",\n",
        "             fontproperties={'family': 'DejaVu Sans', 'size': 11}, y=-0.001)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NBF-zmPKr9fG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos observar al mismo conjunto de datos, pero con un modelo a√∫n m√°s ajustado que el anterior, adhiri√©ndose al comportamiento exacto de la muestra.\n",
        "\n",
        "Este modelo se estar√≠a **sesgando** por su alta fidelidad a las **variaciones** de los datos, que no reflejan el **patr√≥n** que se ha supuesto que subyace a su tendencia.\n",
        "\n",
        "Obtenemos las m√©tricas de evaluaci√≥n para medir su desempe√±o:"
      ],
      "metadata": {
        "id": "HCD8EteQr9fG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se calculan los errores.\n",
        "mse_poly15_train = mean_squared_error(y_train, poly_reg_overfit.predict(X_train))\n",
        "mse_poly15_test = mean_squared_error(y_test, poly_reg_overfit.predict(X_test))\n",
        "\n",
        "poly15_r2_train = poly_reg_overfit.score(X_train, y_train)\n",
        "poly15_r2_test = poly_reg_overfit.score(X_test, y_test)\n",
        "\n",
        "# Se imprimen.\n",
        "print(f\"MSE Entrenamiento: {mse_poly15_train:.4f}\\nMSE Prueba: {mse_poly15_test:.4f}\\n\")\n",
        "print(f\"R¬≤ Entrenamiento: {poly15_r2_train:.4f}\\nR¬≤ Prueba: {poly15_r2_test:.4f}\")"
      ],
      "metadata": {
        "id": "XB2Odq6Zr9fG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se puede notar la diferencia entre los resultados sobre el conjunto de datos de entrenamiento y el de prueba.\n",
        "\n",
        "La comparaci√≥n final lucir√≠a de la siguiente manera:"
      ],
      "metadata": {
        "id": "AYPqVbi6yIpW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crea DataFrame comparativo.\n",
        "df_metrics = pd.DataFrame({\n",
        "    \"Modelo subajustado\": [mse_lin_train, mse_lin_test, r2_train, r2_test],\n",
        "    \"Modelo con mejor ajuste\": [mse_poly_train, mse_poly_test, poly_r2_train, poly_r2_test],\n",
        "    \"Modelo sobreajustado\": [mse_poly15_train, mse_poly15_test, poly15_r2_train, poly15_r2_test]\n",
        "}, index=[\"MSE Entrenamiento\", \"MSE Prueba\", \"R¬≤ Entrenamiento\", \"R¬≤ Prueba\"])\n",
        "\n",
        "# Se imprime.\n",
        "df_metrics"
      ],
      "metadata": {
        "id": "S5Nt_l6Vr9fH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo con mejor ajuste muestra valores aceptables y parecidos para ambos conjuntos de datos.\n",
        "\n",
        "El modelo **subajustado** mantiene m√©tricas deficientes para ambos conjuntos, mientras que el modelo **sobreajustado** difiere de forma significativa en las medidas entre ambos conjuntos."
      ],
      "metadata": {
        "id": "ju7CuOMsyL-t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente, mostramos c√≥mo lucen los tres modelos entrenados en esta sesi√≥n:"
      ],
      "metadata": {
        "id": "xMr1acEgzBud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rrangos de valores para las predicciones de cada modelo\n",
        "x_range = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)  # Para el modelo lineal\n",
        "X_plot_poly = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)  # Para el polinomio grado 3\n",
        "X_plot_overfit = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)  # Para el polinomio grado 15\n",
        "\n",
        "# Predicciones de cada modelo\n",
        "y_line = lin_reg.predict(x_range)\n",
        "y_pred_poly = poly_reg.predict(X_plot_poly)\n",
        "y_pred_poly_overfit = poly_reg_overfit.predict(X_plot_overfit)\n",
        "\n",
        "# Figura con tres subgr√°ficas\n",
        "fig, axs = plt.subplots(1, 3, figsize=(21, 6))\n",
        "\n",
        "# ----- Subgr√°fico 1: Modelo subajustado (Regresi√≥n lineal) -----\n",
        "axs[0].plot(X, y, 'o', color='blue', markersize=6, label='Datos')\n",
        "axs[0].plot(x_range, y_line, color='black', linewidth=2, label='Regresi√≥n lineal')\n",
        "axs[0].set_title(\"Modelado de datos con regresi√≥n lineal (subajuste)\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 16\n",
        "}, pad=15)\n",
        "axs[0].set_xlabel(\"Variable de entrada\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 12\n",
        "}, labelpad=15)\n",
        "axs[0].set_ylabel(\"Variable de salida\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 12\n",
        "}, labelpad=15)\n",
        "axs[0].legend(loc='upper right', prop={\n",
        "    'family': 'DejaVu Sans', 'weight': 'bold', 'size': 11\n",
        "}, frameon=True, framealpha=1, facecolor='#dddddd', shadow=True)\n",
        "axs[0].grid(True)\n",
        "\n",
        "# ----- Subgr√°fico 2: Modelo con mejor ajuste (Polinomio grado 3) -----\n",
        "axs[1].plot(X, y, 'o', color='blue', markersize=6, label='Datos')\n",
        "axs[1].plot(X_plot_poly, y_pred_poly, color='black', linewidth=2, label='Regresi√≥n polinomial (grado 3)')\n",
        "axs[1].set_title(\"Modelado de datos con regresi√≥n polinomial\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 16\n",
        "}, pad=15)\n",
        "axs[1].set_xlabel(\"Variable de entrada\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 12\n",
        "}, labelpad=15)\n",
        "axs[1].set_ylabel(\"Variable de salida\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 12\n",
        "}, labelpad=15)\n",
        "axs[1].legend(loc='upper right', prop={\n",
        "    'family': 'DejaVu Sans', 'weight': 'bold', 'size': 11\n",
        "}, frameon=True, framealpha=1, facecolor='#dddddd', shadow=True)\n",
        "axs[1].grid(True)\n",
        "\n",
        "# ----- Subgr√°fico 3: Modelo sobreajustado (Polinomio grado 15) -----\n",
        "axs[2].plot(X, y, 'o', color='blue', markersize=6, label='Datos')\n",
        "axs[2].plot(X_plot_overfit, y_pred_poly_overfit, color='black', linewidth=2, label='Regresi√≥n polinomial (grado 15)')\n",
        "axs[2].set_title(\"Modelado de datos con regresi√≥n polinomial (sobreajuste)\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 16\n",
        "}, pad=15)\n",
        "axs[2].set_xlabel(\"Variable de entrada\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 12\n",
        "}, labelpad=15)\n",
        "axs[2].set_ylabel(\"Variable de salida\", fontdict={\n",
        "    'family': 'DejaVu Sans', 'color': 'black', 'weight': 'bold', 'size': 12\n",
        "}, labelpad=15)\n",
        "axs[2].legend(loc='lower left', prop={\n",
        "    'family': 'DejaVu Sans', 'weight': 'bold', 'size': 11\n",
        "}, frameon=True, framealpha=1, facecolor='#dddddd', shadow=True)\n",
        "axs[2].grid(True)\n",
        "\n",
        "fig.suptitle(\"Fig. 4 Comparaci√≥n entre regresi√≥n lineal (subajustada) y polinomial (mejor ajuste).\",\n",
        "             fontproperties={'family': 'DejaVu Sans', 'size': 11}, y=0.01)\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3E5YnRhksznV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "WNnVFnSMdKRb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hemos terminado nuestra pr√°ctica en modelos **sobreajustados** y **subajustados**. Hemos **entrenado** y **evaluado** diferentes modelos con deficiencias en el ajuste de sus par√°metros, y visualizado sus diferencias claves en gr√°ficas y m√©tricas de evaluaci√≥n."
      ],
      "metadata": {
        "id": "GOyqpx_OdLpD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚ñ∂ [Regresar a la lecci√≥n](https://dialektico.com/subajuste-sobreajuste-teoria-programacion/) üßô"
      ],
      "metadata": {
        "id": "G8YVS38T9h4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dialektico Machine learning practices ¬© 2025 by Daniel Antonio Garc√≠a Escobar\n",
        "# is licensed under CC BY-NC 4.0. To view a copy of this license,\n",
        "# visit https://creativecommons.org/licenses/by-nc/4.0/\n",
        "\n",
        "# Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International\n",
        "# Public License"
      ],
      "metadata": {
        "id": "mC5uisEVNodI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}